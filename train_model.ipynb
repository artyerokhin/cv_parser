{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# импорты\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Embedding, SpatialDropout1D, Bidirectional, concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель\n",
    "class KerasTextClassifier(BaseEstimator, TransformerMixin):\n",
    "    '''Wrapper class for keras text classification models that takes raw text as input.'''\n",
    "    \n",
    "    def __init__(self, max_words=30000, input_length=1000, emb_dim=20, \n",
    "                 n_classes=4, epochs=5, batch_size=32, model_path=\"neural_model.hdf5\", \n",
    "                tokenizer_path=\"tokenizer.pkl\"):\n",
    "        self.max_words = max_words\n",
    "        self.input_length = input_length\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.epochs = epochs\n",
    "        self.bs = batch_size\n",
    "        self.model_path = model_path\n",
    "        self.model = self._get_model()\n",
    "        self.tokenizer_path = tokenizer_path\n",
    "        self.tokenizer = TfidfVectorizer(token_pattern='[a-zA-zА-яа-яёЁ]+', \n",
    "                                         max_features=self.input_length, \n",
    "                                        ngram_range=(1,3))\n",
    "    \n",
    "    def _get_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.input_length, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(self.n_classes, activation='softmax'))\n",
    "        opt = Adam(learning_rate=0.01)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def _get_sequences(self, texts):\n",
    "        return self.tokenizer.transform(texts).toarray()\n",
    "    \n",
    "    def _preprocess(self, texts):\n",
    "        return [re.sub(r\"\\d\", \"DIGIT\", x) for x in texts]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Fit the vocabulary and the model.\n",
    "        \n",
    "        :params:\n",
    "        X: list of texts.\n",
    "        y: labels.\n",
    "        '''\n",
    "        \n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=self.model_path,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True)\n",
    "        \n",
    "        self.tokenizer.fit(self._preprocess(X))\n",
    "        with open(self.tokenizer_path, 'wb') as handle:\n",
    "            pickle.dump(self.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        seqs = self._get_sequences(self._preprocess(X))\n",
    "        self.model.fit(seqs, y, batch_size=self.bs, epochs=self.epochs, validation_split=0.1, \n",
    "                      callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    def predict_proba(self, X, y=None):\n",
    "        seqs = self._get_sequences(self._preprocess(X))\n",
    "        return self.model.predict(seqs)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def save(self):\n",
    "        with open(self.tokenizer_path, 'wb') as handle:\n",
    "            pickle.dump(self.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        self.model.save(self.model_path)\n",
    "        \n",
    "    def load(self):\n",
    "        with open(self.tokenizer_path, 'rb') as handle:\n",
    "            self.tokenizer = pickle.load(handle)\n",
    "        self.model = load_model(self.model_path)\n",
    "        \n",
    "# top_k accuracy\n",
    "def top_k_accuracy(y_pred, y_true, k=3):\n",
    "    top_preds = np.argsort(y_pred, axis=1)[:, -k:]\n",
    "    return np.mean([int(y_true[n]) in pred for n, pred in enumerate(top_preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обезличенные данные резюме, полученные с hh\n",
    "data = pd.read_csv(\"parsed_data.csv\").append(pd.read_csv(\"parsed_data_ds.csv\"), sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для двух вакансий не было достаточно данных на hh, так что исключим их \n",
    "# для качества классификации и баланса классов\n",
    "data = data.groupby(\"name\").filter(lambda x: len(x) == 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {name: n for n, name in enumerate(data[\"name\"].unique())}\n",
    "reverse_names = {n: name for n, name in enumerate(data[\"name\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"name\"] = data[\"name\"].map(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, stratify=data[\"name\"].values, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Go разработчик': 0, 'Главный инженер по сопровождению': 1, 'Эксперт направления моделирования резервов': 2, 'Data Engineer': 3, 'Аналитик SAS': 4, 'Аналитик банковских рисков': 5, 'Главный инженер по тестированию (автоматизация)': 6, 'Ведущий DevOps инженер': 7, 'Дежурный инженер сопровождения банковских систем': 8, 'Дизайнер мобильных интерфейсов': 9, 'Разработчик Front-end (Middle)': 10, 'Системный аналитик DWH': 11, 'Аналитик системы принятия решений': 12, 'Инженер DevOps': 13, 'Главный разработчик Back-end Java': 14, 'Разработчик RPA': 15, 'Разработчик Front-end (REACT)': 16, 'Системный аналитик': 17, 'Архитектор': 18, 'Системный аналитик (проекты розничного блока)': 19, 'Системный аналитик (базы данных)': 20, 'Аналитик (web приложения)': 21, 'Бизнес-технолог': 22, 'Frontend разработчик': 23, 'Руководитель разработки JAVA': 24, 'Senior Data Scientist': 25}\n"
     ]
    }
   ],
   "source": [
    "# классы - вакансии с сайта https://www.gpbspace.ru/vacancy/\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_model = KerasTextClassifier(epochs=50, n_classes=data[\"name\"].nunique(), input_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 3.1915 - accuracy: 0.1899 - val_loss: 3.0917 - val_accuracy: 0.2821\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.9005 - accuracy: 0.4321 - val_loss: 2.7706 - val_accuracy: 0.3248\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.4891 - accuracy: 0.4824 - val_loss: 2.3876 - val_accuracy: 0.3675\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.0856 - accuracy: 0.5147 - val_loss: 2.1024 - val_accuracy: 0.3761\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.7843 - accuracy: 0.5537 - val_loss: 1.9224 - val_accuracy: 0.3504\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.5816 - accuracy: 0.5764 - val_loss: 1.8077 - val_accuracy: 0.3761\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.4372 - accuracy: 0.6087 - val_loss: 1.7429 - val_accuracy: 0.3932\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.3143 - accuracy: 0.6363 - val_loss: 1.7039 - val_accuracy: 0.3675\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.2153 - accuracy: 0.6524 - val_loss: 1.6548 - val_accuracy: 0.3932\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 1.1249 - accuracy: 0.6933 - val_loss: 1.6435 - val_accuracy: 0.3846\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0462 - accuracy: 0.7047 - val_loss: 1.6335 - val_accuracy: 0.4103\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9596 - accuracy: 0.7474 - val_loss: 1.6222 - val_accuracy: 0.4103\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.9046 - accuracy: 0.7531 - val_loss: 1.6250 - val_accuracy: 0.3761\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.8517 - accuracy: 0.7635 - val_loss: 1.6048 - val_accuracy: 0.3932\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7908 - accuracy: 0.7911 - val_loss: 1.6296 - val_accuracy: 0.4017\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.8006 - val_loss: 1.6105 - val_accuracy: 0.4017\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.8091 - val_loss: 1.6361 - val_accuracy: 0.3932\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.8281 - val_loss: 1.6501 - val_accuracy: 0.4103\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.8291 - val_loss: 1.6434 - val_accuracy: 0.3932\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5765 - accuracy: 0.8414 - val_loss: 1.6651 - val_accuracy: 0.4017\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.8680 - val_loss: 1.6892 - val_accuracy: 0.4017\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.8746 - val_loss: 1.6694 - val_accuracy: 0.4103\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4766 - accuracy: 0.8775 - val_loss: 1.7099 - val_accuracy: 0.4017\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8661 - val_loss: 1.7170 - val_accuracy: 0.4017\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8689 - val_loss: 1.7302 - val_accuracy: 0.4017\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8775 - val_loss: 1.7411 - val_accuracy: 0.4017\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8822 - val_loss: 1.7760 - val_accuracy: 0.4103\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8870 - val_loss: 1.7843 - val_accuracy: 0.4103\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8927 - val_loss: 1.8091 - val_accuracy: 0.4103\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8803 - val_loss: 1.8373 - val_accuracy: 0.3846\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.3481 - accuracy: 0.8927 - val_loss: 1.8376 - val_accuracy: 0.4017\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8993 - val_loss: 1.8479 - val_accuracy: 0.4103\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8936 - val_loss: 1.8630 - val_accuracy: 0.4103\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.8974 - val_loss: 1.8728 - val_accuracy: 0.4274\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.8946 - val_loss: 1.8881 - val_accuracy: 0.4103\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2922 - accuracy: 0.8946 - val_loss: 1.9236 - val_accuracy: 0.4188\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8955 - val_loss: 1.9205 - val_accuracy: 0.4017\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2774 - accuracy: 0.8946 - val_loss: 1.9566 - val_accuracy: 0.4103\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.9069 - val_loss: 1.9683 - val_accuracy: 0.4017\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.9031 - val_loss: 1.9673 - val_accuracy: 0.4103\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.9012 - val_loss: 1.9793 - val_accuracy: 0.4103\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2566 - accuracy: 0.9041 - val_loss: 2.0151 - val_accuracy: 0.4103\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.9012 - val_loss: 2.0325 - val_accuracy: 0.4103\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2421 - accuracy: 0.8984 - val_loss: 2.0212 - val_accuracy: 0.4188\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2413 - accuracy: 0.8946 - val_loss: 2.0237 - val_accuracy: 0.4017\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.9041 - val_loss: 2.0433 - val_accuracy: 0.4017\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8936 - val_loss: 2.0392 - val_accuracy: 0.4274\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9079 - val_loss: 2.0925 - val_accuracy: 0.3932\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 0.2312 - accuracy: 0.9022 - val_loss: 2.0934 - val_accuracy: 0.4017\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9022 - val_loss: 2.1011 - val_accuracy: 0.4017\n"
     ]
    }
   ],
   "source": [
    "text_model.fit(X_train.resume_text, to_categorical(X_train.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.23076923076923"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# топ-3 точность\n",
    "100 * top_k_accuracy(text_model.predict_proba(X_test.resume_text), X_test.name.values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.25641025641026"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# топ-5 точность\n",
    "100 * top_k_accuracy(text_model.predict_proba(X_test.resume_text), X_test.name.values, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем\n",
    "text_model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Ерохин Артем Игоревич\n",
    "\n",
    "Мужчина, 28 лет, родился 6 февраля 1992\n",
    "\n",
    "+7 (925) 5299117\n",
    "ggofat@gmail.com — предпочитаемый способ связи\n",
    "Skype: ggofat\n",
    "\n",
    "Проживает: Москва, м. Котельники\n",
    "Гражданство: Россия, есть разрешение на работу: Россия\n",
    "Не готов к переезду, готов к редким командировкам\n",
    "\n",
    "Желаемая должность и зарплата\n",
    "Data Scientist\n",
    "Информационные технологии, интернет, телеком\n",
    "\n",
    "• Программирование, Разработка\n",
    "• Аналитик\n",
    "\n",
    "Занятость: полная занятость\n",
    "График работы: гибкий график, полный день\n",
    "Желательное время в пути до работы: не более полутора часов\n",
    "\n",
    "Опыт работы — 5 лет 10 месяцев\n",
    "Декабрь 2018 —\n",
    "настоящее время\n",
    "2 года\n",
    "\n",
    "YouDo\n",
    "Москва, www.youdo.ru\n",
    "Data Scientist\n",
    "Основные направления работы:\n",
    "1. Рекомендательные системы;\n",
    "2. Предсказание популярности задания, моделирование цены;\n",
    "3. Кластеризация текстовых данных, выделение намерений, именованных сущностей;\n",
    "4. Классификация заданий по существующей категоризации. Доработка категоризации;\n",
    "5. Автоматизированное противодействие мошенничеству;\n",
    "6. Автоматизация А/Б тестирования;\n",
    "7. Прогнозирование оттока;\n",
    "8. Осуществление процесса разметки данных.\n",
    "\n",
    "Проекты:\n",
    "1. Рекомендации заданий исполнителям;\n",
    "2. Моделирование цены задания: непосредственное предсказание цены и моделирование\n",
    "посредством предсказания спроса и предложения;\n",
    "3. Уточнение и дополнение существующей категоризации на основании данных сервиса;\n",
    "4. Классификатор мошеннических заданий;\n",
    "5. Классификатор категории задания;\n",
    "6. Выделение основного интентов запросов пользователей;\n",
    "7. Прогнозирование оттока исполнителей;\n",
    "8. Разметка данных в Яндекс.Толока.\n",
    "\n",
    "Январь 2018 —\n",
    "Декабрь 2018\n",
    "1 год\n",
    "\n",
    "Стек: Sklearn, LightGBM, Turicreate, Implicit, Spacy, DeepPavlov, Natasha, Яндекс.Толока\n",
    "Fasten Inc. (ГК Везет)\n",
    "Data Scientist\n",
    "\n",
    "Резюме обновлено 17 апреля 2020 в 10:47\n",
    "\n",
    "\f",
    "Основные направления работы:\n",
    "1. Работа с географическими данными дорожной сети и навигационными отметками GPS;\n",
    "2. Работа над задачами трассировки поездки и оценки загруженности дорожной сети;\n",
    "3. Реализация функционала на Python;\n",
    "4. Обучение ML-моделей, а так же оценка результатов их работы\n",
    "5. Консультирование коллег по возникающим вопросам, связанным с анализом данных\n",
    "\n",
    "Проект: Разработка моделей оценки характеристик пользовательской поездки:\n",
    "- оценка скорости ребер графа дорожной сети из данных поездок (очистка данных, выбор способа\n",
    "оценки, получение алгоритма)\n",
    "- \"выравнивание\" полученных простым алгоритмом оценок характеристик посредством машинного\n",
    "обучения (создание скриптом для автоматического обучения модели, \"упаковка\" модели в контейнер)\n",
    "\n",
    "Стек: Sklearn, NetworkX, Keras, Tensorflow Serving, Docker\n",
    "МосгортрансНИИпроект, ГУП\n",
    "Москва\n",
    "Начальник отдела анализа данных\n",
    "- Налаживание процесса очистки, трансформации и хранения данных\n",
    "- Обработка данных с помощью кластера Spark\n",
    "- Обработка и визуализация данных с помощью pandas, sklearn, seaborn, folium, basemap\n",
    "- Работа с AWS\n",
    "- Взаимодействие, общение с другими государственными организациями и держателями данных\n",
    "- Руководство двумя группами аналитиков (анализ данных и транспортное моделирование)\n",
    "- Планирование работы отдела\n",
    "\n",
    "Проекты:\n",
    "1. Матрица корреспонденций НГПТ (наземного городского пассажирского транспорта);\n",
    "2. Решение задачи map-matching для получения данных маршрутов;\n",
    "3. Кластеризация пассажиров НГПТ;\n",
    "4. Разработка базы данных управления;\n",
    "5. Разработка отчетности о качестве обслуживания НГПТ.\n",
    "\n",
    "Стек: NetworkX, Geopandas, Shapely, Pandas, Sklearn, PosrgresSQL (+PostGIS), Spark.\n",
    "МосгортрансНИИпроект, ГУП\n",
    "Москва\n",
    "Старший аналитик\n",
    "- Разработка модели транспортного спроса\n",
    "- Написание скриптов для обработки и очистки данных, визуализация данных\n",
    "- Работа с AWS\n",
    "- Руководство двумя аналитиками\n",
    "Объединенная компания Афиши и Рамблера\n",
    "Москва, rambler.ru/\n",
    "Аналитик\n",
    "- Выполнение задач аналитики проектов Rambler&Co, маркетинга и редакции: настройка систем\n",
    "аналитики, обработка полученных данных и интерпретация результатов;\n",
    "- Постановка задач разработчикам на внесение изменений в код для выполнения задач аналитики,\n",
    "тестирование и выявление ошибок в коде;\n",
    "- Обработка и интерпретация данных различных систем (GoogleAnalytics, Яндекс метрика, ATInternet,\n",
    "Adfox, TNS, Distimo и др);\n",
    "- Работа с API вышеперечисленных систем (GA, Яндекс метрика, Flurry, Adfox, Google webmaster tools);\n",
    "\n",
    "Февраль 2017 —\n",
    "Январь 2018\n",
    "1 год\n",
    "\n",
    "Май 2016 — Январь\n",
    "2017\n",
    "9 месяцев\n",
    "\n",
    "Апрель 2015 — Май\n",
    "2016\n",
    "1 год 2 месяца\n",
    "\n",
    "Ерохин Артем  •  Резюме обновлено 17 апреля 2020 в 10:47\n",
    "\n",
    "\f",
    "- Составление скриптов для выгрузки и визуализации данных (PHP 5.4, Python 2.7);\n",
    "- Статистический анализ результатов А/Б тестирования продуктов;\n",
    "- Визуализация данных в системе Tableau.\n",
    "\n",
    "Октябрь 2014 —\n",
    "Ноябрь 2014\n",
    "2 месяца\n",
    "\n",
    "КонсультантПлюс\n",
    "Москва, www.consultant.ru/wanted/vacancy/\n",
    "Стажер\n",
    "Работа над междисциплинарными проектами со стажерами-юристами\n",
    "\n",
    "Образование\n",
    "Высшее\n",
    "\n",
    "2015\n",
    "\n",
    "МАИ\n",
    "Прикладной математики и физики\n",
    "\n",
    "Электронные сертификаты\n",
    "2017\n",
    "\n",
    "Специализация: Машинное обучение и анализ данных\n",
    "\n",
    "Ключевые навыки\n",
    "Знание языков\n",
    "\n",
    "Русский — Родной\n",
    "Английский — B2 — Средне-продвинутый\n",
    "\n",
    "Навыки\n",
    "\n",
    " Python      SQL      Статистический анализ      Математическая статистика      MySQL \n",
    " Аналитические исследования      Git      Анализ данных      Spark      PostgreSQL \n",
    " Статистика      AWS \n",
    "\n",
    "Дополнительная информация\n",
    "Обо мне\n",
    "\n",
    "Хобби:\n",
    "- Литература, спортивная версия \"Что?Где?Когда?\"\n",
    "\n",
    "Дополнительно:\n",
    "Профиль Kaggle - https://www.kaggle.com/ggofat\n",
    "Github - https://github.com/artyerokhin\n",
    "Спикер конференции DataStart2019 - https://datastart.ru/msk-autumn-2019/\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Go разработчик': 0,\n",
       " 'Главный инженер по сопровождению': 1,\n",
       " 'Эксперт направления моделирования резервов': 2,\n",
       " 'Data Engineer': 3,\n",
       " 'Аналитик SAS': 4,\n",
       " 'Аналитик банковских рисков': 5,\n",
       " 'Главный инженер по тестированию (автоматизация)': 6,\n",
       " 'Ведущий DevOps инженер': 7,\n",
       " 'Дежурный инженер сопровождения банковских систем': 8,\n",
       " 'Дизайнер мобильных интерфейсов': 9,\n",
       " 'Разработчик Front-end (Middle)': 10,\n",
       " 'Системный аналитик DWH': 11,\n",
       " 'Аналитик системы принятия решений': 12,\n",
       " 'Инженер DevOps': 13,\n",
       " 'Главный разработчик Back-end Java': 14,\n",
       " 'Разработчик RPA': 15,\n",
       " 'Разработчик Front-end (REACT)': 16,\n",
       " 'Системный аналитик': 17,\n",
       " 'Архитектор': 18,\n",
       " 'Системный аналитик (проекты розничного блока)': 19,\n",
       " 'Системный аналитик (базы данных)': 20,\n",
       " 'Аналитик (web приложения)': 21,\n",
       " 'Бизнес-технолог': 22,\n",
       " 'Frontend разработчик': 23,\n",
       " 'Руководитель разработки JAVA': 24,\n",
       " 'Senior Data Scientist': 25}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Go разработчик',\n",
       " 1: 'Главный инженер по сопровождению',\n",
       " 2: 'Эксперт направления моделирования резервов',\n",
       " 3: 'Data Engineer',\n",
       " 4: 'Аналитик SAS',\n",
       " 5: 'Аналитик банковских рисков',\n",
       " 6: 'Главный инженер по тестированию (автоматизация)',\n",
       " 7: 'Ведущий DevOps инженер',\n",
       " 8: 'Дежурный инженер сопровождения банковских систем',\n",
       " 9: 'Дизайнер мобильных интерфейсов',\n",
       " 10: 'Разработчик Front-end (Middle)',\n",
       " 11: 'Системный аналитик DWH',\n",
       " 12: 'Аналитик системы принятия решений',\n",
       " 13: 'Инженер DevOps',\n",
       " 14: 'Главный разработчик Back-end Java',\n",
       " 15: 'Разработчик RPA',\n",
       " 16: 'Разработчик Front-end (REACT)',\n",
       " 17: 'Системный аналитик',\n",
       " 18: 'Архитектор',\n",
       " 19: 'Системный аналитик (проекты розничного блока)',\n",
       " 20: 'Системный аналитик (базы данных)',\n",
       " 21: 'Аналитик (web приложения)',\n",
       " 22: 'Бизнес-технолог',\n",
       " 23: 'Frontend разработчик',\n",
       " 24: 'Руководитель разработки JAVA',\n",
       " 25: 'Senior Data Scientist'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = {\n",
    "    0: \"Go разработчик\",\n",
    "    1: \"Главный инженер по сопровождению\",\n",
    "    2: \"Эксперт направления моделирования резервов\",\n",
    "    3: \"Data Engineer\",\n",
    "    4: \"Аналитик SAS\",\n",
    "    5: \"Аналитик банковских рисков\",\n",
    "    6: \"Главный инженер по тестированию (автоматизация)\",\n",
    "    7: \"Ведущий DevOps инженер\",\n",
    "    8: \"Дежурный инженер сопровождения банковских систем\",\n",
    "    9: \"Дизайнер мобильных интерфейсов\",\n",
    "    10: \"Разработчик Front-end (Middle)\",\n",
    "    11: \"Системный аналитик DWH\",\n",
    "    12: \"Аналитик системы принятия решений\",\n",
    "    13: \"Инженер DevOps\",\n",
    "    14: \"Главный разработчик Back-end Java\",\n",
    "    15: \"Разработчик RPA\",\n",
    "    16: \"Разработчик Front-end (REACT)\",\n",
    "    17: \"Системный аналитик\",\n",
    "    18: \"Архитектор\",\n",
    "    19: \"Системный аналитик (проекты розничного блока)\",\n",
    "    20: \"Системный аналитик (базы данных)\",\n",
    "    21: \"Аналитик (web приложения)\",\n",
    "    22: \"Бизнес-технолог\",\n",
    "    23: \"Frontend разработчик\",\n",
    "    24: \"Руководитель разработки JAVA\",\n",
    "    25: \"Senior Data Scientist\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
